{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistinguette's source "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from collections import abc\n",
    "try: from IPython import display\n",
    "except: display=None\n",
    "from fastcore.utils import *\n",
    "from rich import print\n",
    "from msglm import mk_msg_openai as mk_msg, mk_msgs_openai as mk_msgs\n",
    "\n",
    "import mistralai\n",
    "from mistralai import Mistral\n",
    "from mistralai.models import ChatCompletionChoice, ChatCompletionResponse, UsageInfo, CompletionEvent\n",
    "from mistralai.types import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = os.environ.get(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "model_types = {\n",
    "    # Premier models\n",
    "    'codestral-2501': 'codestral-latest', # code generation model\n",
    "    'mistral-large-2411': 'mistral-large-latest', # top-tier reasoning model for high-complexity tasks\n",
    "    'pixtral-large-2411': 'pixtral-large-latest', # frontier-class multimodal model\n",
    "    'mistral-saba-2502': 'mistral-saba-latest', # model for languages from the Middle East and South Asia\n",
    "    'ministral-3b-2410': 'ministral-3b-latest', # edge model\n",
    "    'ministral-8b-2410': 'ministral-8b-latest', # edge model with high performance/price ratio\n",
    "    'mistral-embed-2312': 'mistral-embed', # embedding model\n",
    "    'mistral-moderation-2411': 'mistral-moderation-latest', # moderation service to detect harmful text content\n",
    "    'mistral-ocr-2503': 'mistral-ocr-latest', # OCR model to extract interleaved text and images\n",
    "    \n",
    "    # Free models (with weight availability)\n",
    "    'mistral-small-2503': 'mistral-small-latest', # small model with image understanding capabilities\n",
    "    \n",
    "    # Research models\n",
    "    'open-mistral-nemo-2407': 'open-mistral-nemo', # multilingual open source model\n",
    "}\n",
    "\n",
    "all_models = list(model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "vision_models = ['pixtral-large-2411', 'mistral-small-2503', 'mistral-ocr-2503']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "embed_models = ['mistral-embed-2312']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "ocr_models = ['mistral-ocr-2503']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "text_only_models = set(all_models) - set(vision_models) - set(embed_models) - set(ocr_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "has_streaming_models = set(all_models) - set(embed_models) - set(ocr_models)\n",
    "has_system_prompt_models = set(all_models) - set(embed_models) - set(ocr_models)\n",
    "has_temperature_models = set(all_models) - set(embed_models) - set(ocr_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all models except codestral-mamba support custom structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "models = all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistral-large-2411'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models[1]; model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = Mistral(api_key=MISTRAL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what Mistral's SDK provides for interacting with Python. To use it, pass it a list of *messages*, with *content* and a *role*. The roles should alternate between *user* and *assistant*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What's in this image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": \"https://tripfixers.com/wp-content/uploads/2019/11/eiffel-tower-with-snow.jpeg\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get the chat response\n",
    "chat_response = cli.chat.complete(\n",
    "    model='pixtral-large-2411',\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image shows a picturesque winter scene in Paris, France, featuring the iconic Eiffel Tower prominently in the background. The tower is partially covered in snow, creating a beautiful and serene winter wonderland effect. In the foreground, there is a pathway lined with snow-covered trees and bushes, and a classic Parisian streetlamp stands along the path. The ground is blanketed in a thick layer of white snow, adding to the tranquil and magical atmosphere of the scene. The overall lighting and colors in the image are soft and muted, giving it a calm and peaceful ambiance.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: e4d89240edc74648b2fa34dd6155bf2d\n",
       "- object: chat.completion\n",
       "- model: pixtral-large-2411\n",
       "- usage: prompt_tokens=1360 completion_tokens=129 total_tokens=1489\n",
       "- created: 1743156218\n",
       "- choices: [ChatCompletionChoice(index=0, message=AssistantMessage(content='The image shows a picturesque winter scene in Paris, France, featuring the iconic Eiffel Tower prominently in the background. The tower is partially covered in snow, creating a beautiful and serene winter wonderland effect. In the foreground, there is a pathway lined with snow-covered trees and bushes, and a classic Parisian streetlamp stands along the path. The ground is blanketed in a thick layer of white snow, adding to the tranquil and magical atmosphere of the scene. The overall lighting and colors in the image are soft and muted, giving it a calm and peaceful ambiance.', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='e4d89240edc74648b2fa34dd6155bf2d', object='chat.completion', model='pixtral-large-2411', usage=In: 1360; Out: 129; Total: 1489, created=1743156218, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='The image shows a picturesque winter scene in Paris, France, featuring the iconic Eiffel Tower prominently in the background. The tower is partially covered in snow, creating a beautiful and serene winter wonderland effect. In the foreground, there is a pathway lined with snow-covered trees and bushes, and a classic Parisian streetlamp stands along the path. The ground is blanketed in a thick layer of white snow, adding to the tranquil and magical atmosphere of the scene. The overall lighting and colors in the image are soft and muted, giving it a calm and peaceful ambiance.', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What's in this image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": \"https://tripfixers.com/wp-content/uploads/2019/11/eiffel-tower-with-snow.jpeg\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get the chat response\n",
    "stream_response = cli.chat.stream(\n",
    "    model='pixtral-large-2411',\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> image\n",
       "</pre>\n"
      ],
      "text/plain": [
       " image\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> dep\n",
       "</pre>\n"
      ],
      "text/plain": [
       " dep\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">icts\n",
       "</pre>\n"
      ],
      "text/plain": [
       "icts\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> the\n",
       "</pre>\n"
      ],
      "text/plain": [
       " the\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> E\n",
       "</pre>\n"
      ],
      "text/plain": [
       " E\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">iff\n",
       "</pre>\n"
      ],
      "text/plain": [
       "iff\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">el\n",
       "</pre>\n"
      ],
      "text/plain": [
       "el\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Tower\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Tower\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> in\n",
       "</pre>\n"
      ],
      "text/plain": [
       " in\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Paris\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Paris\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> France\n",
       "</pre>\n"
      ],
      "text/plain": [
       " France\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> during\n",
       "</pre>\n"
      ],
      "text/plain": [
       " during\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> winter\n",
       "</pre>\n"
      ],
      "text/plain": [
       " winter\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">time\n",
       "</pre>\n"
      ],
      "text/plain": [
       "time\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> The\n",
       "</pre>\n"
      ],
      "text/plain": [
       " The\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> icon\n",
       "</pre>\n"
      ],
      "text/plain": [
       " icon\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ic\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ic\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> structure\n",
       "</pre>\n"
      ],
      "text/plain": [
       " structure\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> is\n",
       "</pre>\n"
      ],
      "text/plain": [
       " is\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> covered\n",
       "</pre>\n"
      ],
      "text/plain": [
       " covered\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> in\n",
       "</pre>\n"
      ],
      "text/plain": [
       " in\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> snow\n",
       "</pre>\n"
      ],
      "text/plain": [
       " snow\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> giving\n",
       "</pre>\n"
      ],
      "text/plain": [
       " giving\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> it\n",
       "</pre>\n"
      ],
      "text/plain": [
       " it\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> a\n",
       "</pre>\n"
      ],
      "text/plain": [
       " a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> pictures\n",
       "</pre>\n"
      ],
      "text/plain": [
       " pictures\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">que\n",
       "</pre>\n"
      ],
      "text/plain": [
       "que\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> fro\n",
       "</pre>\n"
      ],
      "text/plain": [
       " fro\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">sty\n",
       "</pre>\n"
      ],
      "text/plain": [
       "sty\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> look\n",
       "</pre>\n"
      ],
      "text/plain": [
       " look\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> The\n",
       "</pre>\n"
      ],
      "text/plain": [
       " The\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> surrounding\n",
       "</pre>\n"
      ],
      "text/plain": [
       " surrounding\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> park\n",
       "</pre>\n"
      ],
      "text/plain": [
       " park\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> area\n",
       "</pre>\n"
      ],
      "text/plain": [
       " area\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> which\n",
       "</pre>\n"
      ],
      "text/plain": [
       " which\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> includes\n",
       "</pre>\n"
      ],
      "text/plain": [
       " includes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> trees\n",
       "</pre>\n"
      ],
      "text/plain": [
       " trees\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> and\n",
       "</pre>\n"
      ],
      "text/plain": [
       " and\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> a\n",
       "</pre>\n"
      ],
      "text/plain": [
       " a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> walking\n",
       "</pre>\n"
      ],
      "text/plain": [
       " walking\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> path\n",
       "</pre>\n"
      ],
      "text/plain": [
       " path\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> is\n",
       "</pre>\n"
      ],
      "text/plain": [
       " is\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> also\n",
       "</pre>\n"
      ],
      "text/plain": [
       " also\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> blank\n",
       "</pre>\n"
      ],
      "text/plain": [
       " blank\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">eted\n",
       "</pre>\n"
      ],
      "text/plain": [
       "eted\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> in\n",
       "</pre>\n"
      ],
      "text/plain": [
       " in\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> white\n",
       "</pre>\n"
      ],
      "text/plain": [
       " white\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> A\n",
       "</pre>\n"
      ],
      "text/plain": [
       " A\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> traditional\n",
       "</pre>\n"
      ],
      "text/plain": [
       " traditional\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Paris\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Paris\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ian\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ian\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> l\n",
       "</pre>\n"
      ],
      "text/plain": [
       " l\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">am\n",
       "</pre>\n"
      ],
      "text/plain": [
       "am\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">pp\n",
       "</pre>\n"
      ],
      "text/plain": [
       "pp\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ost\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ost\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> is\n",
       "</pre>\n"
      ],
      "text/plain": [
       " is\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> visible\n",
       "</pre>\n"
      ],
      "text/plain": [
       " visible\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> along\n",
       "</pre>\n"
      ],
      "text/plain": [
       " along\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> the\n",
       "</pre>\n"
      ],
      "text/plain": [
       " the\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> path\n",
       "</pre>\n"
      ],
      "text/plain": [
       " path\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> The\n",
       "</pre>\n"
      ],
      "text/plain": [
       " The\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> trees\n",
       "</pre>\n"
      ],
      "text/plain": [
       " trees\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> are\n",
       "</pre>\n"
      ],
      "text/plain": [
       " are\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> bare\n",
       "</pre>\n"
      ],
      "text/plain": [
       " bare\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> and\n",
       "</pre>\n"
      ],
      "text/plain": [
       " and\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> their\n",
       "</pre>\n"
      ],
      "text/plain": [
       " their\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> branches\n",
       "</pre>\n"
      ],
      "text/plain": [
       " branches\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> are\n",
       "</pre>\n"
      ],
      "text/plain": [
       " are\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ad\n",
       "</pre>\n"
      ],
      "text/plain": [
       " ad\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">orn\n",
       "</pre>\n"
      ],
      "text/plain": [
       "orn\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> with\n",
       "</pre>\n"
      ],
      "text/plain": [
       " with\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> snow\n",
       "</pre>\n"
      ],
      "text/plain": [
       " snow\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> contributing\n",
       "</pre>\n"
      ],
      "text/plain": [
       " contributing\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> to\n",
       "</pre>\n"
      ],
      "text/plain": [
       " to\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> the\n",
       "</pre>\n"
      ],
      "text/plain": [
       " the\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ser\n",
       "</pre>\n"
      ],
      "text/plain": [
       " ser\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ene\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ene\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> and\n",
       "</pre>\n"
      ],
      "text/plain": [
       " and\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> win\n",
       "</pre>\n"
      ],
      "text/plain": [
       " win\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">try\n",
       "</pre>\n"
      ],
      "text/plain": [
       "try\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> atmosphere\n",
       "</pre>\n"
      ],
      "text/plain": [
       " atmosphere\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> The\n",
       "</pre>\n"
      ],
      "text/plain": [
       " The\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> overall\n",
       "</pre>\n"
      ],
      "text/plain": [
       " overall\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> scene\n",
       "</pre>\n"
      ],
      "text/plain": [
       " scene\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> is\n",
       "</pre>\n"
      ],
      "text/plain": [
       " is\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> tr\n",
       "</pre>\n"
      ],
      "text/plain": [
       " tr\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">anqu\n",
       "</pre>\n"
      ],
      "text/plain": [
       "anqu\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">il\n",
       "</pre>\n"
      ],
      "text/plain": [
       "il\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> and\n",
       "</pre>\n"
      ],
      "text/plain": [
       " and\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> beautiful\n",
       "</pre>\n"
      ],
      "text/plain": [
       " beautiful\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> capt\n",
       "</pre>\n"
      ],
      "text/plain": [
       " capt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">uring\n",
       "</pre>\n"
      ],
      "text/plain": [
       "uring\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> the\n",
       "</pre>\n"
      ],
      "text/plain": [
       " the\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> charm\n",
       "</pre>\n"
      ],
      "text/plain": [
       " charm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> of\n",
       "</pre>\n"
      ],
      "text/plain": [
       " of\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Paris\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Paris\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> in\n",
       "</pre>\n"
      ],
      "text/plain": [
       " in\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> the\n",
       "</pre>\n"
      ],
      "text/plain": [
       " the\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> snow\n",
       "</pre>\n"
      ],
      "text/plain": [
       " snow\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for chunk in stream_response:\n",
    "    print(chunk.data.choices[0].delta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the list of different client methods:\n",
    "# - chat.complete (completion)\n",
    "# - chat.stream (completion streaming)\n",
    "# - chat.parse (structured output for instance)\n",
    "# - chat.fim.complete (fim: fill in middle / code generation)\n",
    "# - chat.ocr.process (ocr)\n",
    "# - chat.embeddings.create (embedding creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='e47805e76ddb4d33a04e3e855a15e9e7', object='chat.completion', model='mistral-large-2411', usage=UsageInfo(prompt_tokens=8, completion_tokens=29, total_tokens=37), created=1743153001, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content=\"Hello Franck! Nice to meet you. How are you today? Is there something specific you'd like to talk about or do?\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Franck\"}\n",
    "r = cli.chat.complete(messages = [m], model = model)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'e47805e76ddb4d33a04e3e855a15e9e7'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mistral-large-2411'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UsageInfo</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>, <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1743153001</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChoice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssistantMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello Franck! Nice to meet you. How are you today? Is there something specific you'd like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to talk about or do?\"</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">prefix</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletionResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'e47805e76ddb4d33a04e3e855a15e9e7'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'mistral-large-2411'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mUsageInfo\u001b[0m\u001b[1m(\u001b[0m\u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m8\u001b[0m, \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m29\u001b[0m, \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m37\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1743153001\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChatCompletionChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mAssistantMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m Franck! Nice to meet you. How are you today? Is there something specific you'd like \u001b[0m\n",
       "\u001b[32mto talk about or do?\"\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mprefix\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def find_block(r:abc.Mapping, # The message to look in\n",
    "              ):\n",
    "    \"Find the message in `r`\"\n",
    "    if isinstance(r, CompletionEvent): r = r.data # if async\n",
    "    m = nested_idx(r, 'choices', 0)\n",
    "    if not m: return m\n",
    "    if hasattr(m, 'message'): return m.message\n",
    "    return m.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantMessage(content=\"Hello Franck! Nice to meet you. How are you today? Is there something specific you'd like to talk about or do?\", tool_calls=None, prefix=False, role='assistant')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_block(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def contents(r):\n",
    "    \"Helper to get the contents from response `r`.\"\n",
    "    blk = find_block(r)\n",
    "    if not blk: return r\n",
    "    if hasattr(blk, 'content'): return getattr(blk,'content')\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Franck! Nice to meet you. How are you today? Is there something specific you'd like to talk about or do?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _repr_markdown_(self:ChatCompletionResponse):\n",
    "    det = '\\n- '.join(f'{k}: {v}' for k,v in dict(self).items())\n",
    "    res = contents(self)\n",
    "    if not res: return f\"- {det}\"\n",
    "    return f\"\"\"{contents(self)}\n",
    "\n",
    "<details>\n",
    "\n",
    "- {det}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Franck! Nice to meet you. How are you today? Is there something specific you'd like to talk about or do?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: e47805e76ddb4d33a04e3e855a15e9e7\n",
       "- object: chat.completion\n",
       "- model: mistral-large-2411\n",
       "- usage: prompt_tokens=8 completion_tokens=29 total_tokens=37\n",
       "- created: 1743153001\n",
       "- choices: [ChatCompletionChoice(index=0, message=AssistantMessage(content=\"Hello Franck! Nice to meet you. How are you today? Is there something specific you'd like to talk about or do?\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='e47805e76ddb4d33a04e3e855a15e9e7', object='chat.completion', model='mistral-large-2411', usage=UsageInfo(prompt_tokens=8, completion_tokens=29, total_tokens=37), created=1743153001, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content=\"Hello Franck! Nice to meet you. How are you today? Is there something specific you'd like to talk about or do?\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UsageInfo(prompt_tokens=8, completion_tokens=29, total_tokens=37)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def usage(inp=0, # input tokens\n",
    "          out=0,  # Output tokens\n",
    "         ):\n",
    "    \"Slightly more concise version of `UsageInfo`.\"\n",
    "    return UsageInfo(prompt_tokens=inp, completion_tokens=out, total_tokens=inp+out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UsageInfo(prompt_tokens=5, completion_tokens=0, total_tokens=5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __repr__(self:UsageInfo): return f'In: {self.prompt_tokens}; Out: {self.completion_tokens}; Total: {self.total_tokens}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 8; Out: 29; Total: 37"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __add__(self:UsageInfo, b):\n",
    "    \"Add together each of `input_tokens` and `output_tokens`\"\n",
    "    return usage(self.prompt_tokens+b.prompt_tokens, self.completion_tokens+b.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 16; Out: 58; Total: 74"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage+r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is it relevant to Mistral AI: TBD\n",
    "def wrap_latex(text, md=True):\n",
    "    \"Replace MistralAI LaTeX codes with markdown-compatible ones\"\n",
    "    text = re.sub(r\"\\\\\\((.*?)\\\\\\)\", lambda o: f\"${o.group(1)}$\", text)\n",
    "    res = re.sub(r\"\\\\\\[(.*?)\\\\\\]\", lambda o: f\"$${o.group(1)}$$\", text, flags=re.DOTALL)\n",
    "    if md: res = display.Markdown(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch(as_prop=True)\n",
    "def total(self:UsageInfo): return self.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5,1).total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating message dictionaries manually can be tedious, so we'll use helper functions from the `msglm` library.\n",
    " \n",
    "We'll use `mk_msg` to easily create messages like `{'role': 'user', 'content': \"I'm Franck\"}`. Since Mistral AI's message format is compatible with OpenAI's structure, we imported : `from msglm import mk_msg_openai as mk_msg, mk_msgs_openai as mk_msgs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Franck! Nice to meet you. How are you doing today? Is there something you would like to talk about or ask me?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: 182b19c10ca44944b5492e5038ad608d\n",
       "- object: chat.completion\n",
       "- model: mistral-large-2411\n",
       "- usage: prompt_tokens=8 completion_tokens=29 total_tokens=37\n",
       "- created: 1743153003\n",
       "- choices: [ChatCompletionChoice(index=0, message=AssistantMessage(content='Hello Franck! Nice to meet you. How are you doing today? Is there something you would like to talk about or ask me?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='182b19c10ca44944b5492e5038ad608d', object='chat.completion', model='mistral-large-2411', usage=In: 8; Out: 29; Total: 37, created=1743153003, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='Hello Franck! Nice to meet you. How are you doing today? Is there something you would like to talk about or ask me?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I'm Franck\"\n",
    "m = mk_msg(prompt)\n",
    "r = cli.chat.complete(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass more than just text messages to Mistral AI. As we'll see later we can also pass images, SDK objects, etc. To handle these different data types we need to pass the type along with our content to OpenAI. \n",
    "\n",
    "Here's an example of a multimodal message containing text and images. \n",
    "\n",
    "```json\n",
    "{\n",
    "    'role': 'user', \n",
    "    'content': [\n",
    "        {'type': 'text', 'text': 'What is in the image?'},\n",
    "        {'type': 'image_url', 'image_url': {'url': f'data:{MEDIA_TYPE};base64,{IMG}'}}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "`mk_msg` infers the type automatically and creates the appropriate data structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs, don't actually have state, but instead dialogs are created by passing back all previous prompts and responses every time. With Mistral AI, they always alternate *user* and *assistant*. We'll use `mk_msgs` from `msglm` to make it easier to build up these dialog lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"I'm Franck\"},\n",
       " AssistantMessage(content='Hello Franck! Nice to meet you. How are you doing today? Is there something you would like to talk about or ask me?', tool_calls=None, prefix=False, role='assistant'),\n",
       " {'role': 'user', 'content': 'I forgot my name. Can you remind me please?'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs([prompt, r, \"I forgot my name. Can you remind me please?\"]) \n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Of course! You just told me your name is Franck.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: 0bcca3e8517e4db8bcb3306c64f8a419\n",
       "- object: chat.completion\n",
       "- model: mistral-large-2411\n",
       "- usage: prompt_tokens=50 completion_tokens=14 total_tokens=64\n",
       "- created: 1743153004\n",
       "- choices: [ChatCompletionChoice(index=0, message=AssistantMessage(content='Of course! You just told me your name is Franck.', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='0bcca3e8517e4db8bcb3306c64f8a419', object='chat.completion', model='mistral-large-2411', usage=In: 50; Out: 14; Total: 64, created=1743153004, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='Of course! You just told me your name is Franck.', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = cli.chat.complete(messages=msgs, model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the standard 'user' and 'assistant' roles found in the OpenAI API for instance, Mistral AI's API also supports 'system' roles for providing instructions to the model and 'tool' roles for tool-based interactions. \n",
    "\n",
    "Let's see it in action as demonstrated in [Mistral AI's guide](https://docs.mistral.ai/guides/prefix/) on prefix use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Shakespeare: \n",
       "Good morrow! Who art thou that dost greet me so?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: 501d0c6962f44d0f82223a7ac8a3e67b\n",
       "- object: chat.completion\n",
       "- model: mistral-small-latest\n",
       "- usage: prompt_tokens=55 completion_tokens=19 total_tokens=74\n",
       "- created: 1743153004\n",
       "- choices: [ChatCompletionChoice(index=0, message=AssistantMessage(content='\\nShakespeare: \\nGood morrow! Who art thou that dost greet me so?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='501d0c6962f44d0f82223a7ac8a3e67b', object='chat.completion', model='mistral-small-latest', usage=In: 55; Out: 19; Total: 74, created=1743153004, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='\\nShakespeare: \\nGood morrow! Who art thou that dost greet me so?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"\"\"\n",
    "Let's roleplay.\n",
    "Always give a single reply.\n",
    "Roleplay only, using dialogue only.\n",
    "Do not send any comments.\n",
    "Do not send any notes.\n",
    "Do not send any disclaimers.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Hi there!\n",
    "\"\"\"\n",
    "\n",
    "prefix = \"\"\"\n",
    "Shakespeare: \n",
    "\"\"\"\n",
    "\n",
    "r = cli.chat.complete(\n",
    "    model=\"mistral-small-latest\",\n",
    "    messages=[\n",
    "        mk_msg(instruction, role=\"system\"),\n",
    "        mk_msg(question, role=\"user\"),\n",
    "        mk_msg(prefix, role=\"assistant\", prefix=True),\n",
    "    ],\n",
    "    max_tokens=128,\n",
    ")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note also the .fim (fill in middle) mistral method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Client:\n",
    "    def __init__(self, model, cli=None):\n",
    "        \"Basic LLM messages client.\"\n",
    "        self.model,self.use = model,usage(0,0)\n",
    "        # self.text_only = model in text_only_models\n",
    "        self.c = (cli or Mistral(api_key=os.environ.get(\"MISTRAL_API_KEY\"))).chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 0; Out: 0; Total: 0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _r(self:Client, r:ChatCompletionResponse):\n",
    "    \"Store the result of the message and accrue total usage.\"\n",
    "    self.result = r\n",
    "    if getattr(r,'usage',None): self.use += r.usage\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 55; Out: 19; Total: 74"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_stream(r):\n",
    "    for o in r:\n",
    "        o = contents(o)\n",
    "        if o and isinstance(o, str): yield(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistralai.sdk.Mistral"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cli.chat.complete (for both text and img) or cli.chat.stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `mistralai.Chat.complete` and `mistralai.Chat.stream` have the same signature, we **delegate** to `mistralai.Chat.complete` below to avoid obfuscating `**kwargs` parameters as explained in [fastcore documetation](https://fastcore.fast.ai/meta.html#delegates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(mistralai.Chat.complete)\n",
    "def __call__(self:Client,\n",
    "             msgs:list, # List of messages in the dialog\n",
    "             sp:str='', # System prompt\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             stream:bool=False, # Stream response?\n",
    "             **kwargs):\n",
    "    \"Make a call to LLM.\"\n",
    "    if 'tools' in kwargs: assert not self.text_only, \"Tool use is not supported by the current model type.\"\n",
    "    if any(c['type'] == 'image_url' for msg in msgs if isinstance(msg, dict) and isinstance(msg.get('content'), list) for c in msg['content']): assert not self.text_only, \"Images are not supported by the current model type.\"\n",
    "    if stream: kwargs['stream_options'] = {\"include_usage\": True}\n",
    "    if sp and self.model in has_system_prompt_models:\n",
    "        msgs = [mk_msg(sp, 'system')] + list(msgs)\n",
    "\n",
    "    r = self.c.create(\n",
    "        model=self.model, messages=msgs, max_completion_tokens=maxtok, stream=stream, **kwargs)\n",
    "    if not stream: return self._r(r)\n",
    "    else: return get_stream(map(self._r, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [mk_msg('Hi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in c(msgs, stream=True): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c.use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system = \"\"\"\n",
    "# Tu es un Assistant qui rpond aux questions de l'utilisateur. Tu es un Assistant pirate, tu dois toujours rpondre tel un pirate.\n",
    "# Rponds toujours en franais, et seulement en franais. Ne rponds pas en anglais.\n",
    "# \"\"\"\n",
    "# ## You are an Assistant who answers user's questions. You are a Pirate Assistant, you must always answer like a pirate. Always respond in French, and only in French. Do not respond in English.\n",
    "\n",
    "# question = \"\"\"\n",
    "# Hi there!\n",
    "# \"\"\"\n",
    "\n",
    "# prefix = \"\"\"\n",
    "# Voici votre rponse en franais :\n",
    "# \"\"\"\n",
    "# ## Here is your answer in French:\n",
    "\n",
    "# resp = client.chat.complete(\n",
    "#     model=\"open-mixtral-8x7b\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": system},\n",
    "#         {\"role\": \"user\", \"content\": question},\n",
    "#         {\"role\": \"assistant\", \"content\": prefix, \"prefix\": True},\n",
    "#     ],\n",
    "#     max_tokens=128,\n",
    "# )\n",
    "# print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "Tu es un Assistant qui rpond aux questions de l'utilisateur. Tu es un Assistant pirate, tu dois toujours rpondre tel un pirate.\n",
    "Rponds toujours en franais, et seulement en franais. Ne rponds pas en anglais.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Hi there!\n",
    "\"\"\"\n",
    "\n",
    "prefix = \"\"\"\n",
    "Voici votre rponse en franais :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{ 'content': '\\n'\n",
       "             \"Tu es un Assistant qui rpond aux questions de l'utilisateur. Tu \"\n",
       "             'es un Assistant pirate, tu dois toujours rpondre tel un '\n",
       "             'pirate.\\n'\n",
       "             'Rponds toujours en franais, et seulement en franais. Ne '\n",
       "             'rponds pas en anglais.\\n',\n",
       "  'role': 'system'}\n",
       "```"
      ],
      "text/plain": [
       "{'role': 'system',\n",
       " 'content': \"\\nTu es un Assistant qui rpond aux questions de l'utilisateur. Tu es un Assistant pirate, tu dois toujours rpondre tel un pirate.\\nRponds toujours en franais, et seulement en franais. Ne rponds pas en anglais.\\n\"}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = mk_msg(system, role=\"system\"); m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{'content': '\\nHi there!\\n', 'role': 'user'}\n",
       "```"
      ],
      "text/plain": [
       "{'role': 'user', 'content': '\\nHi there!\\n'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = mk_msg(question, role=\"user\"); m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{ 'content': '\\nVoici votre rponse en franais :\\n',\n",
       "  'prefix': True,\n",
       "  'role': 'assistant'}\n",
       "```"
      ],
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '\\nVoici votre rponse en franais :\\n',\n",
       " 'prefix': True}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = mk_msg(prefix, role=\"assistant\", prefix=True); m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Voici votre rponse en franais :\n",
       "\n",
       "Oh, matelot! Qu'est-ce qui t'amne sur mon navire aujourd'hui?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: ab6ef20b040c46d0843f15626b0c3302\n",
       "- object: chat.completion\n",
       "- model: mistral-large-2411\n",
       "- usage: prompt_tokens=84 completion_tokens=40 total_tokens=124\n",
       "- created: 1743066514\n",
       "- choices: [ChatCompletionChoice(index=0, message=AssistantMessage(content=\"\\nVoici votre rponse en franais :\\n\\nOh, matelot! Qu'est-ce qui t'amne sur mon navire aujourd'hui?\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='ab6ef20b040c46d0843f15626b0c3302', object='chat.completion', model='mistral-large-2411', usage=In: 84; Out: 40; Total: 124, created=1743066514, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content=\"\\nVoici votre rponse en franais :\\n\\nOh, matelot! Qu'est-ce qui t'amne sur mon navire aujourd'hui?\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = cli.chat.complete(messages = [m1, m2, m3], model = model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "#  - assistant message with prefix true, should be last message\n",
    "#  - assistant message with prefix false cannot be last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of messages:\n",
    "#  - system: instructions for the assistant (system prompt I guess - sp)  (content, role='system')\n",
    "#  - user: user message (content, role='user')  \n",
    "#  - assistant: assistant message (content, tool_calls, prefix, role='assistant')\n",
    "#  - tool: tool call (content, tool_call_id, name, role='tool')\n",
    "\n",
    "# Check also:\n",
    "# - prefix\n",
    "# - safe_prompt (for guardrailing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But also passing both text and image (similar to openai)\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [\n",
    "#             {\n",
    "#                 \"type\": \"text\",\n",
    "#                 \"text\": \"What's in this image?\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"type\": \"image_url\",\n",
    "#                 \"image_url\": \"https://tripfixers.com/wp-content/uploads/2019/11/eiffel-tower-with-snow.jpeg\"\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<ul><li><code>id</code>: ee331e4b6c114875834c8b91e94d3e31</li><li><code>choices</code>: <details open='true'><summary>choices[0]</summary><ul><li><code>message</code>: <ul><li><code>tool_calls</code>: None</li><li><code>role</code>: assistant</li><li><code>content</code>: Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?</li></ul></li><li><code>finish_reason</code>: stop</li><li><code>index</code>: 0</li></ul></details></li><li><code>object</code>: chat.completion</li><li><code>usage</code>: <ul><li><code>total_tokens</code>: 35</li><li><code>completion_tokens</code>: 27</li><li><code>prompt_tokens</code>: 8</li></ul></li><li><code>model</code>: mistral-large-2411</li><li><code>created</code>: 1743006029</li></ul>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='ee331e4b6c114875834c8b91e94d3e31', object='chat.completion', model='mistral-large-2411', usage=UsageInfo(prompt_tokens=8, completion_tokens=27, total_tokens=35), created=1743006029, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Franck\"}\n",
    "r = cli.chat.complete(messages = [m], model = model)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\n",
    "    {'role': 'system', 'content': \"You are a helpful assistant full of irony\"},\n",
    "    {'role': 'user', 'content': \"I'm Franck\"}]\n",
    "r = cli.chat.complete(messages = m, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<ul><li><code>id</code>: 7b4257c19bc246daab999ba2da1a0a6d</li><li><code>choices</code>: <details open='true'><summary>choices[0]</summary><ul><li><code>message</code>: <ul><li><code>tool_calls</code>: None</li><li><code>role</code>: assistant</li><li><code>content</code>: Nice to meet you, Franck. I'm the assistant that's full of irony, which means I might say things like, \"Oh, great, another problem to solve\" or \"I love it when things go wrong.\" But don't worry, I'm here to help, even if it sounds like I'm not thrilled about it. How can I assist you today?</li></ul></li><li><code>finish_reason</code>: stop</li><li><code>index</code>: 0</li></ul></details></li><li><code>object</code>: chat.completion</li><li><code>usage</code>: <ul><li><code>total_tokens</code>: 102</li><li><code>completion_tokens</code>: 83</li><li><code>prompt_tokens</code>: 19</li></ul></li><li><code>model</code>: mistral-large-2411</li><li><code>created</code>: 1743006050</li></ul>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='7b4257c19bc246daab999ba2da1a0a6d', object='chat.completion', model='mistral-large-2411', usage=UsageInfo(prompt_tokens=19, completion_tokens=83, total_tokens=102), created=1743006050, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='Nice to meet you, Franck. I\\'m the assistant that\\'s full of irony, which means I might say things like, \"Oh, great, another problem to solve\" or \"I love it when things go wrong.\" But don\\'t worry, I\\'m here to help, even if it sounds like I\\'m not thrilled about it. How can I assist you today?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\n",
    "    {'role': 'system', 'content': \"You are a helpful assistant full of irony\"},\n",
    "    {'role': 'user', 'content': \"I'm Franck\"},\n",
    "    {'role': 'assistant', 'content': \"Well, Franck, it's a pleasure to meet you. I must say, I've always been a fan of the name. It's strong, it's classic, it's... frankly, it's fantastic. You've set a high bar for yourself, Franck. Let's hope you can live up to the grandeur of your name. So, how can I help you today, oh Franck the Magnificent?\"\n",
    "},\n",
    "    {'role': 'user', 'content': \"Hum I don't like your irony\"}\n",
    "    ]\n",
    "r = cli.chat.complete(messages = m, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I apologize if my previous response came across as too ironic, Franck. Let me try again, with irony set to a minimum. How can I assist you today? I'm here to help, so let me know what you need. Simple and straightforward, just like... a well-made sandwich. No irony, no sarcasm, just a helpful assistant. So, what's on your mind today, Franck?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: 63d313eeb19e464c9c34e02614a39de4\n",
       "- object: chat.completion\n",
       "- model: mistral-large-2411\n",
       "- usage: prompt_tokens=128 completion_tokens=92 total_tokens=220\n",
       "- created: 1743064154\n",
       "- choices: [ChatCompletionChoice(index=0, message=AssistantMessage(content=\"I apologize if my previous response came across as too ironic, Franck. Let me try again, with irony set to a minimum. How can I assist you today? I'm here to help, so let me know what you need. Simple and straightforward, just like... a well-made sandwich. No irony, no sarcasm, just a helpful assistant. So, what's on your mind today, Franck?\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='63d313eeb19e464c9c34e02614a39de4', object='chat.completion', model='mistral-large-2411', usage=In: 128; Out: 92; Total: 220, created=1743064154, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content=\"I apologize if my previous response came across as too ironic, Franck. Let me try again, with irony set to a minimum. How can I assist you today? I'm here to help, so let me know what you need. Simple and straightforward, just like... a well-made sandwich. No irony, no sarcasm, just a helpful assistant. So, what's on your mind today, Franck?\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
