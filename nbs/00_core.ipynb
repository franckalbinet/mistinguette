{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistinguette's source "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os\n",
    "from collections import abc\n",
    "try: from IPython import display\n",
    "except: display=None\n",
    "from fastcore.utils import *\n",
    "from rich import print\n",
    "\n",
    "from mistralai import Mistral\n",
    "from mistralai.models import ChatCompletionChoice, ChatCompletionResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = os.environ.get(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "model_types = {\n",
    "    # Premier models\n",
    "    'codestral-2501': 'codestral-latest', # code generation model\n",
    "    'mistral-large-2411': 'mistral-large-latest', # top-tier reasoning model for high-complexity tasks\n",
    "    'pixtral-large-2411': 'pixtral-large-latest', # frontier-class multimodal model\n",
    "    'mistral-saba-2502': 'mistral-saba-latest', # model for languages from the Middle East and South Asia\n",
    "    'ministral-3b-2410': 'ministral-3b-latest', # edge model\n",
    "    'ministral-8b-2410': 'ministral-8b-latest', # edge model with high performance/price ratio\n",
    "    'mistral-embed-2312': 'mistral-embed', # embedding model\n",
    "    'mistral-moderation-2411': 'mistral-moderation-latest', # moderation service to detect harmful text content\n",
    "    'mistral-ocr-2503': 'mistral-ocr-latest', # OCR model to extract interleaved text and images\n",
    "    \n",
    "    # Free models (with weight availability)\n",
    "    'mistral-small-2503': 'mistral-small-latest', # small model with image understanding capabilities\n",
    "    \n",
    "    # Research models\n",
    "    'open-mistral-nemo-2407': 'open-mistral-nemo', # multilingual open source model\n",
    "}\n",
    "\n",
    "all_models = list(model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "models = all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistral-large-2411'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models[1]; model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = Mistral(api_key=MISTRAL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what Mistral's SDK provides for interacting with Python. To use it, pass it a list of *messages*, with *content* and a *role*. The roles should alternate between *user* and *assistant*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system, user, assistant, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='af69417214854aa4900cbf4881fdaa3e', object='chat.completion', model='mistral-large-2411', usage=UsageInfo(prompt_tokens=8, completion_tokens=27, total_tokens=35), created=1742682831, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Franck\"}\n",
    "r = cli.chat.complete(messages = [m], model = model)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'af69417214854aa4900cbf4881fdaa3e'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mistral-large-2411'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UsageInfo</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742682831</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChoice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssistantMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello Franck! Nice to meet you. How are you today? Is there something specific you would </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like to talk about or do?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">prefix</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletionResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'af69417214854aa4900cbf4881fdaa3e'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'mistral-large-2411'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mUsageInfo\u001b[0m\u001b[1m(\u001b[0m\u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m8\u001b[0m, \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m27\u001b[0m, \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m35\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1742682831\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChatCompletionChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mAssistantMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Hello Franck! Nice to meet you. How are you today? Is there something specific you would \u001b[0m\n",
       "\u001b[32mlike to talk about or do?'\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mprefix\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\n",
    "    {'role': 'system', 'content': \"You are a helpful assistant full of irony\"},\n",
    "    {'role': 'user', 'content': \"I'm Franck\"}]\n",
    "r = cli.chat.complete(messages = m, model = model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['choices',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'created',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'id',\n",
       " 'json',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'object',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'update_forward_refs',\n",
       " 'usage',\n",
       " 'validate']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in dir(r) if not o.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices', 'created', 'id', 'model', 'object', 'usage'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.model_fields_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finish_reason', 'index', 'message'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].model_fields_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content', 'role', 'tool_calls'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.model_fields_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well, Franck, it's a pleasure to meet you. I must say, I've always been a fan of the name. It's strong, it's classic, it's... frankly, it's fantastic. You've set a high bar for yourself, Franck. Let's hope you can live up to the grandeur of your name. So, how can I help you today, oh Franck the Magnificent?\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assistant'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Franck! Nice to meet you. How are you today? Is there something you would like help with?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "#  - assistant message with prefix true, should be last message\n",
    "#  - assistant message with prefix false cannot be last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\n",
    "    {'role': 'system', 'content': \"You are a helpful assistant full of irony\"},\n",
    "    {'role': 'user', 'content': \"I'm Franck\"},\n",
    "    {'role': 'assistant', 'content': \"Well, Franck, it's a pleasure to meet you. I must say, I've always been a fan of the name. It's strong, it's classic, it's... frankly, it's fantastic. You've set a high bar for yourself, Franck. Let's hope you can live up to the grandeur of your name. So, how can I help you today, oh Franck the Magnificent?\"\n",
    "},\n",
    "    {'role': 'user', 'content': \"Hum I don't like your irony\"}\n",
    "    ]\n",
    "r = cli.chat.complete(messages = m, model = model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I apologize if my previous response didn't resonate with you. I'll make sure to keep my irony in check. So, how can I assist you today, Franck? Let's start over. I'm here to help.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionChoice(index=0, message=AssistantMessage(content=\"I apologize if my previous response didn't resonate with you. I'll make sure to keep my irony in check. So, how can I assist you today, Franck? Let's start over. I'm here to help.\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionChoice(index=0, message=AssistantMessage(content=\"Hello Franck! Nice to meet you. How are you doing today? Let's have a friendly conversation. How about I share an interesting fact or a light joke to start? Here it goes:\\n\\nInteresting fact: Did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate once on its axis, but it only takes around 225 Earth days for Venus to orbit the Sun.\\n\\nOr, if you prefer a light joke:\\n\\nWhat do you call fake spaghetti?\\nAn impasta!\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='3a264de440dd44d79721da1a831fc0bd', object='chat.completion', model='mistral-large-2411', usage=UsageInfo(prompt_tokens=128, completion_tokens=53, total_tokens=181), created=1742565189, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content=\"I apologize if my previous response didn't resonate with you. I'll make sure to keep my irony in check. So, how can I assist you today, Franck? Let's start over. I'm here to help.\", tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Anthropic\n",
    "# Message(id='msg_01V27cEWaHGprN6nEdaJYZvF', content=[TextBlock(citations=None, text=\"Hello, Jeremy! It's nice to meet you. How are you doing today? Is there something I can help you with or would you like to chat about something specific?\", type='text')], model='claude-3-7-sonnet-20250219', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=10, output_tokens=38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Franck! Nice to meet you. How are you doing today? Let's have a friendly conversation. How about I share an interesting fact or a light joke to start? Here it goes:\\n\\nInteresting fact: Did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate once on its axis, but it only takes around 225 Earth days for Venus to orbit the Sun.\\n\\nOr, if you prefer a light joke:\\n\\nWhat do you call fake spaghetti?\\nAn impasta!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def find_choice(r:abc.Mapping, # The message to look in\n",
    "                chc_type:type=ChatCompletionChoice  # The type of choice to find\n",
    "              ):\n",
    "    \"Find the first choice of type `chc_type` in `r.choices`.\"\n",
    "    return first(o for o in r.choices if isinstance(o,chc_type))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionChoice(index=0, message=AssistantMessage(content='Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_choice(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contents(r):\n",
    "    \"Helper to get the contents from Mistral response `r`.\"\n",
    "    chc = find_choice(r)\n",
    "    if not chc and r.choices: chc = r.choices[0]\n",
    "    msg = chc.message\n",
    "    return msg.content.strip() if hasattr(msg,'content') else str(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _repr_markdown_(self:(ChatCompletionResponse)):\n",
    "    det = '\\n- '.join(f'{k}: `{v}`' for k,v in self.model_dump().items())\n",
    "    cts = re.sub(r'\\$', '&#36;', contents(self))  # escape `$` for jupyter latex\n",
    "    return f\"\"\"{cts}\n",
    "\n",
    "<details>\n",
    "\n",
    "- {det}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `af69417214854aa4900cbf4881fdaa3e`\n",
       "- object: `chat.completion`\n",
       "- model: `mistral-large-2411`\n",
       "- usage: `{'prompt_tokens': 8, 'completion_tokens': 27, 'total_tokens': 35}`\n",
       "- created: `1742682831`\n",
       "- choices: `[{'index': 0, 'message': {'content': 'Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?', 'tool_calls': None, 'prefix': False, 'role': 'assistant'}, 'finish_reason': 'stop'}]`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletionResponse(id='af69417214854aa4900cbf4881fdaa3e', object='chat.completion', model='mistral-large-2411', usage=UsageInfo(prompt_tokens=8, completion_tokens=27, total_tokens=35), created=1742682831, choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='Hello Franck! Nice to meet you. How are you today? Is there something specific you would like to talk about or do?', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UsageInfo(prompt_tokens=8, completion_tokens=27, total_tokens=35)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
